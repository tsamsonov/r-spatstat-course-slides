{
  "hash": "dd30a698502ebde4a6b839eef21f1c9a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Пространственная регшрессия\"\nsubtitle: \"Пространственная статистика\"\ndate: today\ndate-format: long\nauthor: \"Самсонов Тимофей Евгеньевич\"\nexecute:\n  echo: false\n  freeze: true\nengine: knitr\nformat:\n  revealjs: \n    theme: [default, custom.scss]\n    margin: 0.2\n    width: 1280\n    height: 720\n    slide-number: true\n    footer: \"Самсонов Т. Е. Пространственная статистика: курс лекций\"\n    header-includes: <link rel=\"stylesheet\" media=\"screen\" href=\"https://fontlibrary.org//face/pt-sans\" type=\"text/css\"/>\nbibliography: references.yaml\nmainfont: PT Sans\n---\n\n\n## Базовые компоненты\n\n\n\n\n\n## Особенности случайных процессов в пространстве\n\n-   **Пространственная зависимость** *(spatial dependence)* — наличие автокорреляции наблюдений. Выражается в невыполнении условия независимости остатков линейной регрессии. Устраняется посредством *пространственной регрессии (spatial regression)*.\n\n-   **Пространственная гетерогенность** *(spatial heterogeneity)* — нестационарность процессов, порождающих наблюдаемую переменную. Выражается в неэффективности постоянных коэффициентов линейной регрессии. Устраняется постредством *географически взвешенной регрессии (geographically weighted regression)*.\n\n## Линейная регрессия\n\nПусть дан вектор $\\mathbf{y} = \\{y_1, y_2, ... y_n\\}$ измерений зависимой переменной, а также матрица $\\mathbf{X} = \\{x_{ij}\\}$ размером $n \\times m$, состоящая из значений $m$ независимых переменных для $n$ измерений. В этом случае модель линейной регрессии может быть записана как\n\n$$\\mathbf{y} = \\mathbf{X} \\boldsymbol\\beta + \\boldsymbol\\epsilon,$$\n\nгде:\n\n-   $\\boldsymbol\\beta$ — вектор коэффициентов регрессии;\n\n-   $\\boldsymbol\\epsilon$ — вектор случайных ошибок, независимо распределенных относительно среднего значения в нуле.\n\n<!-- ## Многомерное нормальное распределение -->\n\n<!-- Многомерное нормальное распределение (МНР) $k$-мерного случайного вектора $\\mathbf{X} = (X_1, ..., X_k)^T$ обозначается как: -->\n\n<!-- $$\\mathbf{X}\\ \\sim \\mathcal{N}_k(\\boldsymbol\\mu,\\, \\boldsymbol\\Sigma)$$ -->\n\n<!-- МНР определяется двумя параметрами: -->\n\n<!-- - __математическое ожидание__ ( $k$-мерный вектор): -->\n\n<!-- $$\\boldsymbol\\mu = \\operatorname{E}[\\mathbf{X}] = [ \\operatorname{E}[X_1], \\operatorname{E}[X_2], \\ldots, \\operatorname{E}[X_k]]^{\\rm T}$$ -->\n\n<!-- - __ковариационная матрица__ (размером $k \\times k$): -->\n\n<!-- $$\\boldsymbol\\Sigma = \\operatorname{E} [(\\mathbf{X} - \\boldsymbol\\mu)( \\mathbf{X} - \\boldsymbol \\mu)^{\\rm T}] =  [ \\operatorname{Cov}[X_i, X_j]; 1 \\le i,j \\le k ]$$ -->\n\n<!-- ## Стандартный нормальный случайный вектор -->\n\n<!-- Вещественнозначный случайный вектор $\\mathbf{X} = (X_1, ..., X_k)^T$ называется __стандартным нормальным случайным вектором__, если все его компоненты $X_n$ независимы друг от друга и подчиняются стандартному случаю нормального закона распределения с нулевым математическим ожиданием и единичной дисперсией для всех $n$: -->\n\n<!-- $$X_n \\sim \\mathcal{N}(0, 1)$$ -->\n\n<!-- В модели линейной регрессии: -->\n\n<!-- $$\\boldsymbol\\epsilon \\sim \\mathcal{N}_k(0, \\sigma^2 \\mathbf{I}),$$ -->\n\n<!-- где $I$ — единичная матрица размером $k \\times k$. -->\n\n<!-- ## Расширение класса регрессионных моделей -->\n\n<!-- $$\\boldsymbol\\epsilon \\sim \\mathcal{N}_k(0, \\sigma^2 \\mathbf{I})$$ -->\n\n<!-- Однако если данные получены измерениями по пространству, остатки регрессии могут демонстрировать пространственную ассоциацию (зависимость), как правило свидетельствующую о наличии дополнительных неучтённых факторов. Это означает, что обычная модель регрессии недостаточно хорошо объясняет зависимость. -->\n\n<!-- Чтобы моделировать зависимость остатков, необходим более широкий класс моделей: -->\n\n<!-- $$\\boldsymbol\\epsilon \\sim \\mathcal{N}_k(0, \\mathbf{C}),$$ -->\n\n<!-- где $\\mathbf{C}$ — любая допустимая ковариационная матрица. -->\n\n## Пример\n\nПроцент домохозяйств, находящихся во владении\n\n![](images/tyne_ownerocc.png){width=\"65%\"}\n\n## Пример\n\nУровень безработицы\n\n![](images/tyne_unempl.png){width=\"65%\"}\n\n## Пример\n\nОбычная линейная регрессия\n\n![](images/tyne_regr.png){width=\"75%\"}\n\n## Пример\n\nОстатки регрессии\n\n![](images/tyne_resid.png){width=\"65%\"}\n\n<!-- ## Расширение класса регрессионных моделей -->\n\n<!-- $$\\boldsymbol\\epsilon \\sim \\mathcal{N}_k(0, \\mathbf{C})$$ -->\n\n<!-- Данная модель решает проблему независимости остатков, однако порождает две других проблемы: -->\n\n<!-- - Если зависимость остатков имеет пространственный характер (ассоциированы остатки в территориально близких локациях), то матрица $\\mathbf{C}$ характер этой зависимости не отражает в явном виде. -->\n\n<!-- - Вектор коэффициентов регрессии $\\boldsymbol\\beta$ может быть получен путем минимизации $\\mathbf{y} - \\mathbf{X}\\boldsymbol\\beta$ путем решения $\\beta = \\big(\\mathbf{X}^T \\mathbf{CX} \\big)^{-1} \\mathbf{X}^T \\mathbf{X y}$. Однако это требует знания ковариационной матрицы, которая обычно неизвестна. Поэтому как $\\mathbf{C}$, так и $\\boldsymbol\\beta$ калибруются по выборке. -->\n\n## Пространственная регрессия\n\nДля того чтобы учесть пространственную автокорреляцию остатков, в модель линейной регрессии добавляется компонента **пространственной авторегрессии** *(spatial autoregression)*, которая моделирует *пространстенный лаг*:\n\n$$\\mathbf{y} = \\underbrace{\\mathbf{X} \\mathbf{\\beta}}_{тренд} + \\underbrace{\\color{red}{\\rho\\mathbf{Wy}}}_{сигнал} +  \\underbrace{\\mathbf{\\epsilon}}_{шум},$$\n\n-   $\\rho$ — коэффициент регрессии, отражающий степень пространственной автокорреляции\n\n-   $\\mathbf{W}$ — матрица пространственных весов\n\n> Полученная модель называется моделью **пространственной регрессии** (*spatial regression*).\n\nКомпоненты модели (тренд, сигнал и шум) называются **предикторами**.\n\n## Пространственная регрессия\n\nДля получения коэффициентов $\\boldsymbol\\beta$ и $\\rho$ выполним ряд преобразований:\n\n$$\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} +  \\mathbf{\\epsilon}\\\\\n\\mathbf{y} - \\rho\\mathbf{Wy} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}\\\\\n(\\mathbf{I} - \\rho\\mathbf{W})\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}$$\n\nПредполагая, что матрица $(\\mathbf{I} - \\rho\\mathbf{W})$ инвертируема, получаем систему уравнений пространственной регрессии:\n\n$$\\color{red}{\\boxed{\\color{blue}{\\mathbf{y} = (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta} + (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{\\epsilon}}}}$$\n\nДанная модель идентична обычной регрессии $\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}$, но в ней независимые переменные и ошибки линейно трансформированы умножением на $(\\mathbf{I} - \\rho\\mathbf{W})^{-1}$.\n\n<!-- --- -->\n\n<!-- ## Пространственная регрессия -->\n\n<!-- $$\\mathbf{y} = (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta} + (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{\\epsilon}$$ -->\n\n<!-- Трансформированная ошибка модели будет иметь ковариационную матрицу -->\n\n<!-- $$\\mathbf{C} = \\sigma^2 \\Big[\\big(\\mathbf{I} - \\rho \\mathbf{W}\\big)^{-1}\\Big]^T (\\mathbf{I} - \\rho\\mathbf{W})^{-1}$$ -->\n\n<!-- - Если ковариационная матрица функционально зависит от параметра $\\rho$, то она отражает пространственную структуру автокорреляции ошибок. -->\n\n<!-- - Ковариационная матрица должна быть положительно определенной. Для полученного выражения это будет выполняться в случае если $|\\rho| \\leq 1$ (Griffith, 1988). -->\n\n## Пространственная регрессия\n\n$$\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} +  \\mathbf{\\epsilon}$$\n\nДля нахождения коэффициентов $\\boldsymbol\\beta$ и $\\rho$ используется минимизация квадрата случайной компоненты, которую можно представить как $\\mathbf{\\epsilon} = \\mathbf{y} - \\mathbf{X} \\mathbf{\\beta} - \\rho\\mathbf{Wy}$:\n\n$$\\sum_i \\Bigg(y_i - \\sum_j \\beta_j x_{ij} - \\rho \\sum_j w_{ij} y_j \\Bigg)^2$$\n\nЗадача решается в 2 этапа:\n\n-   находится оптимальное значение $\\rho$;\n-   находится оптимальное значение $\\boldsymbol\\beta$ путем подстановки в вышеуказанное выражение.\n\n## Пространственная фильтрация\n\nМодель пространственной регрессии может быть использована для осуществления **пространственной фильтрации** — убирания автокорреляционной составляющей.\n\nДля этого необходимо авторегрессионную компоненту (пространственный лаг) перенести в левую часть уравнения:\n\n$$\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} + \\mathbf{\\epsilon}\\\\\n\\mathbf{y}^* = \\mathbf{y} - \\rho\\mathbf{Wy} = \\mathbf{X} \\mathbf{\\beta} + \\mathbf{\\epsilon}$$\n\n-   Пространственная фильтрация бывает полезна, когда наблюдается несоответствие масштаба наблюдений и масштаба процесса.\n\n-   Например, статистика по показателю, контролируемому на региональном уровне, собирается по муниципалитетам. В этом случае фильтрация позволяет подобрать параметры $\\mathbf{\\beta}$, учитывающие наличие высокой пространственной автокорреляци.\n\n## Оценка географического соседства\n\nПримеры иллюстрируются по данным Кировской области:\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-1-1.png){fig-align='left' width=480}\n:::\n:::\n\n\n## Оценка географического соседства\n\nВ целом, можно выделить три большие группы методов:\n\n-   Соседи по смежности\n\n-   Соседи по графу\n\n-   Соседи по метрике\n\n## Соседство по смежности\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](images/QueenRook.png){fig-align='left' width=880}\n:::\n:::\n\n\n**Соседство по смежности** основано на топологических отношениях между объектами и применяется при анализе данных, приуроченных к площадным единицам.\n\n## Соседство по смежности\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='left' width=960}\n:::\n:::\n\n\n## Соседство по графу\n\n**Соседство по графу** основано на отношениях объектов в [триангуляции Делоне](https://ru.wikipedia.org/wiki/Триангуляция_Делоне).\n\n::: columns\n::: {.column width=\"50%\"}\nВ эту же категорию попадают всевозможные фильтрации триангуляции Делоне, которые удаляют из нее ребра, не удовлетворяющие заданным критериям:\n\n-   сфера влияния\n\n-   граф Гэбриела\n\n-   относительное соседство\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='left' width=480}\n:::\n:::\n\n:::\n:::\n\n## Соседство по триангуляции Делоне\n\n::: columns\n::: {.column width=\"50%\"}\nСоседство по триангуляции реализуется путем триангулирования центров территориальных единиц.\n\n-   Внешние ребра идут по выпуклой оболочке множества центров\n\n-   Очень много связей между единицами, которые реально соседними не являются\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='left' width=480}\n:::\n:::\n\n:::\n:::\n\n## Сфера влияния\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](images/SphereOfInfluence.png){fig-align='left' width=1166}\n:::\n:::\n\n\nРебра триангуляции, инцидентные (примыкающие к) данной вершине, сохраняются только если $D \\leq 2D_{min}$\n\n## Соседство по сфере влияния\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-7-1.png){fig-align='left' width=960}\n:::\n:::\n\n\n## Граф Гэбриела\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](images/Gabriel.png){fig-align='left' width=1074}\n:::\n:::\n\n\nВ каждом треугольнике ребро сохранятся только тогда, когда построенная на нем окружность не включает третью точку треугольника\n\n## Соседство по графу Гэбриела\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-9-1.png){fig-align='left' width=960}\n:::\n:::\n\n\n## Граф относительного соседства\n\n::: columns\n::: {.column width=\"50%\"}\nПолучается путем фильтрации триангуляции Делоне по следующему правилу:\n\n> ребро $A$, соединяющее две вершины $p$ и $q$, будет удалено, если найдется третья вершина $r$, такая что расстояния от нее до $p$ и $q$ ( $B$ и $C$ соответственно) окажутся короче, чем $A$, то есть: $A > B$ **and** $A > C$.\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-10-1.png){fig-align='left' width=480}\n:::\n:::\n\n:::\n:::\n\n## Соседи по метрике\n\nПоиск соседей по метрике — наиболее простой способ определения соседства.\n\nДля его использования необходимо задать метрику (как правило, расстояние между точками), а также критерий фильтрации связей:\n\n-   по количеству ( $k$ ближайших)\n\n-   по расстоянию (не ближе чем $d_1$, но и не далее чем $d_2$).\n\n## Соседи по количеству\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-11-1.png){fig-align='left' width=960}\n:::\n:::\n\n\n## Соседи по расстоянию\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-12-1.png){fig-align='left' width=960}\n:::\n:::\n\n\n## Пространственные веса\n\n-   Пространственные веса характеризуют силу связи между единицами.\n\n-   Если единицы не являются соседними (по выбранному правилу), то пространственный вес их связи будет равен нулю. Во всех остальных случаях веса будут ненулевыми.\n\n-   Поскольку теоретически каждая единица может быть связана с любой другой единицей, распространена форма представления весов в виде матрицы $W$ размером $N \\times N$, где $N$ -- число единиц.\n\n-   На пересечении $i$-й строки и $j$-го столбца матрицы располагается вес связи между $i$-й и $j$-й единицей.\n\n## Бинарная матрица\n\nЕсли связь есть, то ее вес равен единице (1), если нет — нулю (0)\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-13-1.png){fig-align='left' width=672}\n:::\n:::\n\n\n## Нормированная матрица\n\nВес $j$-й единицы по отношению к $i$-й равен $1/n_i$, где $n_i$ — количество соседей у $i$.\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-14-1.png){fig-align='left' width=576}\n:::\n:::\n\n\n## Пространственная автокорреляция\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-15-1.png){fig-align='left' width=1152}\n:::\n:::\n\n\n## Индекс Морана (Moran's I)\n\nАнализ пространственной автокорреляции осуществляется, как правило, путем вычисления индекса Морана (Moran's I):\n\n$$I = \\frac{n \\sum^n_{i=1} \\sum^n_{j=i} w_{ij} (y_i - \\bar y)(y_j - \\bar y)}{ \\Big[\\sum^n_{i=1} \\sum^n_{j=i} w_{ij}\\Big] \\Big[\\sum^n_{i=1} (y_i - \\bar y)^2\\Big]}$$\n\nгде:\n\n-   $n$ — количество единиц,\n-   $w_{ij}$ — вес пространственной связи между $i$-й и $j$-й единицей,\n-   $y_i$ — значение в $i$-й единице,\n-   $\\bar y$ — выборочное среднее по всем единицам\n\n## Коэффициент корреляции Пирсона\n\nОбратим внимание на то, что индекс Морана по сути и форме записи похож на линейный коэффициент корреляции Пирсона, в котором перебираются все пары соответствующих друг другу значений из рядов $X = \\{x_i\\}$ и $Y = \\{y_i\\}$:\n\n$$r_{xy} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar x)(y_i - \\bar y)}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar x)^2} \\sqrt{\\sum_{i=1}^{n}(y_i - \\bar y)^2}}$$\n\n## Индекс Морана (Moran's I)\n\nИндекс Морана для нормально распределенных данных лежит в диапазоне от -1 до 1:\n\n-   +1 означает детерминированную прямую зависимость — группировку схожих (низких или высоких) значений.\n\n-   0 означает абсолютно случайное распределение (*CSR — complete spatial randomness*)\n\n-   -1 означает детерминированную обратную зависимость — идеальное перемешивание низких и высоких значений, напоминающее шахматную доску\n\n**Математическое ожидание** индекса Морана для случайных данных равно $E[I] = -1/(n-1)$\n\n## Индекс Морана (Moran's I)\n\nИндекс Морана для данных за февраль:\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# Выбираем данные за февраль\nfeb = mun |> \n  filter(month == 'Февраль')\n\n# Вычисление индекса (тест) Морана\nmoran.test(feb$nsick, W)\n## \n## \tMoran I test under randomisation\n## \n## data:  feb$nsick  \n## weights: W    \n## \n## Moran I statistic standard deviate = 5.0335, p-value = 0.0000002408\n## alternative hypothesis: greater\n## sample estimates:\n## Moran I statistic       Expectation          Variance \n##        0.52118132       -0.02564103        0.01180194\n```\n:::\n\n\n## Перестановочный тест Морана\n\nЗначения перемешиваются между территориальными единицами и далее строится гистограмма распределения. Значимость индека Морана оценивается по отклонению реального значения от среднего по случайным симуляциям\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-17-1.png){fig-align='left' width=960}\n:::\n:::\n\n\n## Перестановочный тест Морана\n\nЗначения перемешиваются между территориальными единицами и далее строится гистограмма распределения. Значимость индека Морана оценивается по отклонению\n\n\n::: {.cell layout-align=\"left\"}\n\n```\n## \n## \tMonte-Carlo simulation of Moran I\n## \n## data:  feb$nsick \n## weights: W  \n## number of simulations + 1: 10001 \n## \n## statistic = 0.52118, observed rank = 10001, p-value = 0.00009999\n## alternative hypothesis: greater\n```\n:::\n\n\n## Диаграмма рассеяния Морана\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-19-1.png){fig-align='left' width=480}\n:::\n:::\n\n:::\n\n::: {.column width=\"50%\"}\nПо оси $X$ откладывается значение в каждой территориальной единице, в по оси $Y$ — ее пространственный лаг (средневзвешенное значение по всем ее соседям).\n\n-   Тангенс угла наклона прямой равен значению индекса Морана.\n\n-   Выделенные фонариком единицы вносят наибольший вклад в индекс\n:::\n:::\n\n## Пространственная авторегрессия\n\nПоиск уравнения пространственной регрессии и его авторегрессионной составляющей может быть выполнен посредством функций `spautolm()` и `lagsarlm()` из пакета **spatialreg**:\n\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n(model = lagsarlm(nsick ~ 1, data = feb, listw = W))\n## \n## Call:\n## lagsarlm(formula = nsick ~ 1, data = feb, listw = W)\n## Type: lag \n## \n## Coefficients:\n##         rho (Intercept) \n##    0.704957 1223.330336 \n## \n## Log likelihood: -346.2344\n```\n:::\n\n\n## Пространственная авторегрессия\n\nНа основе полученной модели можно построить карты пространственной авторегрессии и остатков:\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-21-1.png){fig-align='left' width=960}\n:::\n:::\n\n\n## Предсказание на основе простр. регрессии\n\nРазличают три вида предсказания:\n\n-   **Внутривыборочное** (in-sample) используется для вычисления предикторов на основе данных, использованных для построения модели пространственной регрессии.\n\n-   **Прогнозное** (prevision/forecast) используется для вычисления предикторов на основе новых данных по тем же выборочным единицам\n\n-   **Вневыборочное** (out-of-sample) используется для вычисления предикторов с включением новых выборочных единиц\n\n## Внутривыборочное предсказание\n\n**Внутривыброчное** (in-sample) предсказание не требует дополнительных действий, поскольку оно осуществляется непосредственно моделью пространственной регрессии:\n\n$$\\underbrace{\\mathbf{y}}_{отклик} = \\underbrace{\\mathbf{X} \\mathbf{\\beta}}_{тренд} + \\underbrace{\\rho\\mathbf{Wy}}_{сигнал} + \\underbrace{\\mathbf{\\epsilon}}_{шум}$$\n\n## Прогнозное предсказание\n\n**Прогонозное** (forecast) предсказание требует последовательного вычисления тренда, переменной отклика и сигнала. Для этого необходимо выполнить следующие преобразования:\n\n$$\\mathbf{y} = \\mathbf{X} \\mathbf{\\beta} + \\rho\\mathbf{Wy} + \\mathbf{\\epsilon}\\\\\n(\\mathbf{I} - \\rho\\mathbf{W})\\mathbf{y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{\\epsilon}\\\\\n\\mathbf{y} = (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta} + (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{\\epsilon}$$\n\nПрогноз с использованием полученного выражения делается в предположении, что $\\mathbf{\\epsilon} = 0$. В этом случае, имея новые данные тренда $\\mathbf{X}\\mathbf{\\beta}$, вычисляем сначала $\\mathbf{y} = (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta}$ и далее находим сигнал их умножением:\n\n$$\\rho\\mathbf{Wy} = \\rho\\mathbf{W} (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta}$$\n\n## Вневыборочное предсказание\n\n::: columns\n::: {.column width=\"50%\"}\n![](images/outsample.png){width=\"100%\"}\n:::\n\n::: {.column width=\"50%\"}\n*Goulard, M., Laurent, T., Thomas-Agnan, C.*, 2017. **About predictions in spatial autoregressive models: optimal and almost optimal strategies**. Spatial Economic Analysis 12, 304–325. https://doi.org/10.1080/17421772.2017.1300679\n:::\n:::\n\n## Вневыборочное предсказание\n\n**Вневыборочное** (out-of-sample) предсказание связано с решением ситуации, когда есть данные по независимым переменным $\\mathbf{X_S}$ и отклику $\\mathbf{Y_S}$ по одним единицам и данные только по независимым переменным $\\mathbf{X_O}$ для другой части единиц. Требуется найти отклик $\\mathbf{Y_O}$ для этих единиц.\n\nДля решения этой задачи необходимо стратифицировать вектора данных и матрицу весов:\n\n$$\\begin{bmatrix}\\mathbf{Y_S}\\\\ \\color{red}{\\mathbf{Y_O}}\\end{bmatrix} = \\rho \\begin{bmatrix}\\mathbf{W_{SS}} & \\mathbf{W_{SO}} \\\\ \\mathbf{W_{OS}} & \\mathbf{W_{OO}}\\end{bmatrix} \\begin{bmatrix}\\mathbf{Y_S}\\\\\\color{red}{\\mathbf{Y_O}}\\end{bmatrix} + \\begin{bmatrix}\\mathbf{X_S}\\\\\\mathbf{X_O}\\end{bmatrix} \\mathbf{\\beta} + \\begin{bmatrix}\\mathbf{\\epsilon_S}\\\\\\mathbf{\\epsilon_O}\\end{bmatrix}$$ Красным цветом выделены неизвестные данные.\n\n## Вневыборочное предсказание\n\nДля вневыборочного предсказания используется ранее полученная модель прогнозирования $\\mathbf{y} = (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta}$. Однако ее необходимо также представить в стратифицированном виде:\n\n$$\\begin{bmatrix}\\mathbf{Y_S}\\\\ \\mathbf{Y_O}\\end{bmatrix} = (\\mathbf{I} - \\rho\\mathbf{W})^{-1}\\mathbf{X}\\mathbf{\\beta}=\\\\=\\begin{bmatrix}\\mathbf{I_{SS}} - \\rho\\mathbf{W_{SS}} & -\\rho\\mathbf{W_{SO}} \\\\ -\\rho\\mathbf{W_{OS}} & \\mathbf{I_{OO}} - \\rho\\mathbf{W_{OO}}\\end{bmatrix}^{-1} \\begin{bmatrix}\\mathbf{X_S}\\\\\\mathbf{X_O}\\end{bmatrix}\\beta=\\\\=\\begin{bmatrix}\\mathbf{A} & \\mathbf{B} \\\\ \\mathbf{C} & \\mathbf{D}\\end{bmatrix}^{-1} \\begin{bmatrix}\\mathbf{X_S}\\\\\\mathbf{X_O}\\end{bmatrix}\\beta$$\n\n## Вневыборочное предсказание\n\n$$\\begin{bmatrix}\\mathbf{Y_S}\\\\ \\mathbf{Y_O}\\end{bmatrix} = \\begin{bmatrix}\\mathbf{A} & \\mathbf{B} \\\\ \\mathbf{C} & \\mathbf{D}\\end{bmatrix}^{-1} \\begin{bmatrix}\\mathbf{X_S}\\\\\\mathbf{X_O}\\end{bmatrix}\\beta$$Раскрыв данное выражение, можно получить предсказания для выборочных и вневыборочных единиц:\n\n$$\\mathbf{Y_S} = (\\mathbf{A} - \\mathbf{BD}^{-1} \\mathbf{C})^{-1} \\mathbf{X_S} \\mathbf{\\beta} -(\\mathbf{A} - \\mathbf{BD}^{-1} \\mathbf{C})^{-1} \\mathbf{BD}^{-1} \\mathbf{X_O} \\mathbf{\\beta}$$\n\n$$\\mathbf{Y_O} = (\\mathbf{D} - \\mathbf{CA}^{-1} \\mathbf{B})^{-1} \\mathbf{X_O} \\mathbf{\\beta} - (\\mathbf{D} - \\mathbf{CA}^{-1} \\mathbf{B})^{-1} \\mathbf{C} \\mathbf{A}^{-1} \\mathbf{X_S} \\mathbf{\\beta}$$\n\n## Исходные данные (пример)\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-22-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Исходные данные (пример)\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-23-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Исходные данные (пример)\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-24-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Диаграмма рассеяния\n\nДиаграмма рассеяния показывает соотношение переменных\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-25-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Линейная регрессия\n\nЛинейная регрессия дает аппроксимацию зависимости\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-26-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\nКоэффициент корреляции равен $-0.696$.\n\n## Линейная регрессия\n\nЛинейная регрессия дает аппроксимацию зависимости\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-27-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\nКоэффициент корреляции равен $-0.574$.\n\n## Линейная регрессия\n\nДля модели\n\n$$\n\\texttt{CRIME} = \\beta_0 + \\beta_1 \\texttt{INC} + \\beta_2 \\texttt{HOVAL}\n$$\n\nполучается следующая диагностика:\n\n\n::: {.cell layout-align=\"left\"}\n\n```\n##               Estimate Std. Error                   Pr(>|t|)\n## (Intercept) 68.6189611  4.7354861 0.000000000000000000921089\n## INC         -1.5973108  0.3341308 0.000018289595070842137403\n## HOVAL       -0.2739315  0.1031987 0.010874504909753494874547\n```\n:::\n\n\nТ.е. модель принимает следующий вид:\n\n$$\n\\texttt{CRIME} = 68.619 -1.597~\\texttt{INC} - 0.274~\\texttt{HOVAL}\n$$\n\n## Линейная регрессия\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-29-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Линейная регрессия\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-30-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Линейная регрессия\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-31-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Остатки регрессии\n\n::: columns\n::: {.column width=\"50%\"}\n::: callout-important\n## Важно\n\nЕсли остатки от регрессии образуют пространственный рисунок, это значит, что независимых переменных недостаточно для предсказания исследуемой величины. Необходимо учитывать пространственную зависимость.\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-32-1.png){fig-align='left' width=1500}\n:::\n:::\n\n:::\n:::\n\nПри анализе карт остатков регрессии обращают внимание на то, меняются ли они плавно по пространству, есть ли выраженный пространственный тренд и зависимость значений соседних единиц.\n\n## Пространственные веса\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-33-1.png){fig-align='left' width=1200}\n:::\n:::\n\n\n## Пространственные веса\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-34-1.png){fig-align='left' width=1200}\n:::\n:::\n\n\n## Индекс Морана\n\n::: columns\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-35-1.png){fig-align='left' width=900}\n:::\n:::\n\n\nИндекс Морана равен $0.500$\n:::\n\n::: {.column width=\"50%\"}\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-36-1.png){fig-align='left' width=900}\n:::\n:::\n\n\nИндекс Морана равен $0.222$\n:::\n:::\n\nПоскольку остатки регрессии по-прежнему автокоррелированы, можно сделать вывод о том, что независимые переменные не объясняют полностью величину преступности.\n\n## Пространственная регрессия\n\nДля нашего случая модель будет иметь вид:\n\n$$\n\\texttt{CRIME} = 45.603 -1.049~\\texttt{INC} - 0.266~\\texttt{HOVAL} + 0.423~W~\\texttt{CRIME}\n$$\n\n\n::: {.cell layout-align=\"left\"}\n\n```\n## \n## Call:\n## lagsarlm(formula = CRIME ~ INC + HOVAL, data = reg, listw = Wstand)\n## Type: lag \n## \n## Coefficients:\n##         rho (Intercept)         INC       HOVAL \n##   0.4233254  45.6032484  -1.0487282  -0.2663348 \n## \n## Log likelihood: -182.674\n```\n:::\n\n\n## Пространственная регрессия\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-38-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Пространственная регрессия\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-39-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Пространственная регрессия\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-40-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Пространственная регрессия\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-41-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Пространственная регрессия\n\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-42-1.png){fig-align='left' width=1500}\n:::\n:::\n\n\n## Остатки пространств. регрессии\n\n**Индекс Морана** для остатков пространств. регрессии равен $0.033$.\n\n::: columns\n::: {.column width=\"40%\"}\nАвтокорреляционная составляющая практически полностью учтена в модели пространственной регрессии. Предсказательная сила модели улучшена.\n:::\n\n::: {.column width=\"60%\"}\n\n::: {.cell layout-align=\"left\"}\n::: {.cell-output-display}\n![](03_SpatialRegression_files/figure-revealjs/unnamed-chunk-43-1.png){fig-align='left' width=900}\n:::\n:::\n\n:::\n:::\n",
    "supporting": [
      "03_SpatialRegression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}