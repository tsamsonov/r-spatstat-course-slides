<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Точечные процессы</title>
    <meta charset="utf-8" />
    <meta name="author" content="Тимофей Самсонов" />
    <meta name="date" content="2022-04-22" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Точечные процессы
## Пространственная статистика
### Тимофей Самсонов
### 2022-04-22

---




## Точечный паттерн

__Точечный паттерн__ _(point pattern)_ представляет собой множество точек в `\(\mathbb{R}^2\)`, обозначаемое _малой_ жирной буквой:

`$$\mathbf{x} = \{x_1, x_2,...x_n\}$$`
- Количество точек `\(n = n(\mathbf{x})\)` может быть любым неотрицательным числом

- Множество является неупорядоченным (индексы чисто условны)

- Допускаются дубликаты (совпадающие точки), однако большинство методов рассчитаны на то, что дубликатов в множестве нет.

---

## Точечный паттерн

Если `\(\mathbf{x}\)` представляет точечный паттерн и `\(B\)` — это некий регион, то `\(\mathbf{x} \cap B\)` есть подмножество `\(\mathbf{x}\)`, состоящее из точек, попадающих в `\(B\)`:

![:scale 40%](images/pregion.png)

В данном случае количество точек, попадающих в `\(B\)`, равняется  `\(n = n(\mathbf{x} \cap B)\)`

---

## Точечные процессы

&gt; __ Точечным процессом__ называется случайный процесс, реализациями которого являются точечные паттерны

__Конечный точечный процесс__ _(finite point process)_ — это точечный процесс, каждая реализация которого представляет собой точечный паттерн с конечным числом точек. При этом для любой области `\(B\)` количество точек `\(\mathbf{x} \cap B\)` представляет собой случайную величину с определимыми параметрами.

__Локально конечный точечный процесс__ имеет конечное число точек в любой ограниченной области `\(B\)` (более мягкое утверждение). Реализацией такого процесса является _локально конечный точечный паттерн_.

---

## Равномерно случайные точки

Простейшим точечным процессом является процесс `\(U = (U_1, U_2)\)`, каждая реализация которого включает одну точку `\(u = (u_1, u_2)\)`. 

Случайная точка будет _равномерно_ распределена в пространственной облсти `\(W\)`, если ее координаты `\((U_1, U_2)\)` имеют совместную плотность распределения, которая постоянна в пределах `\(W\)` и равна нулю за ее пределами. 

Поскольку интеграл плотности распределения равен 1, величина постоянной будет равна `\(1/|W|\)`:

`$$f(u_1, u_2) = \begin{cases}
  1/|W|,~\text{если}~(u_1, u_2) \in W\\
  0, ~\text{в противном случае}
\end{cases}$$`

---

## Равномерно случайные точки

Если `\(B\)` представляет собой тестовую область в `\(W\)`, то вероятность того, что точка `\(U\)` попадет в `\(B\)`, будет равна:

`$$\mathbb{P}\{U \in B \} = \int_B f(u_1, u_2) du_1 du_2 = \\ = \frac{1}{|W|} \int_B 1 du_1 du_2 = \frac{|B|}{|W|}$$`
- эта вероятность равна доле площади `\(B\)` в `\(W\)`

- вероятность зависит только от площади, и не зависит от положения и формы области `\(B\)` 

---

### Биномиальный точечный процесс

__Биномиальным__ называется точечный процесс `\(\mathbf{X} = \{X_1,..., X_n\}\)`, реализации которого содержат `\(n\)` точек.

![Baddeley et. al., 2016](images/pbinomial.png)

Чтобы точки были распределены равномерно по пространству, необходимо выполнение двух условий:

- `\(X_1,...,X_n\)` представляют собой _независимые_ случайные величины
- Каждая из этих величин _равномерно_ распределена в пределах `\(W\)`.

---

### Биномиальный точечный процесс

Если `\(B\)` представляет собой тестовую область, то количество `\(n(\mathbf{X} \cap B)\)` случайных точек, попавших в `\(B\)`, будет равняться количеству индексов `\(i\)` таких, что `\(X_i \in B\)`.

Чтобы определить вероятностное распределение `\(n(\mathbf{X} \cap B)\)`, рассмотрим эту величину как количество успешных исходов в `\(n\)` независимых испытаниях. Будем считать «успехом» исход, при котором случайная точка `\(X_i\)` попадает в `\(B\)`. 

Если испытания независимы и равномерно распределены, то вероятность успеха равна `\(p = |B| / |W|\)` и величина  `\(n(\mathbf{X} \cap B)\)` имеет _биномиальный закон распределения_:

`$$\mathbb{P}\{n(\mathbf{X} \cap B) = k\} = 
  \left(
    \begin{array}{c}
      n \\
      k
    \end{array}
  \right) p^k (1-p)^{n-k}\color{grey}{, k = 0, 1, ..., n}$$`
  
Биномиальный коэффициент равен числу сочетаний из `\(n\)` по `\(k\)`:
`$$\left(
    \begin{array}{c}
      n \\
      k
    \end{array}
  \right) = \frac{n!}{(n-k)!~k!}$$`

---

### Пуассоновский процесс

__Однородный пуассоновский точечный процесс__ (homogeneous Poisson point process), или _абсолютная пространственная случайность_ (complete spatial randomness — CSR) характеризуется следующими свойствами:

- __гомогенность__: размещение точек не имеет пространственных закономерностей
- __независимость__: результат реализации процесса в одной области не оказывает влияние на результат реализации в других областях

![Baddeley et. al., 2016](images/ppoisson.png)

---

### Пуассоновский процесс

__Однородность__ _(гомогенность)_ означает, что ожидаемое количество точек, попадающих в регион `\(B\)` должно быть пропорционально его площади:

`$$\operatorname E[n(\mathbf{X} \cap B)] = \lambda |B|$$`
Параметр `\(\lambda\)` представляет собой среднее количество точек на единицу площади — __интенсивность точечного процесса__.

&gt; В отличие от биномиального процесса, полностью случайный (Пуассоновский) процесс характеризуется _случайным количеством точек_.

---

### Пуассоновский процесс

__Пространственная независимость__ означает, что количества точек в двух неперекрывающихся областях `\(A\)` и `\(B\)` являются независимыми случайными переменными:

`$$n(\mathbf{X} \cap A) \not\sim n(\mathbf{X} \cap B),~A \cap B = \emptyset$$`
&gt; Для биномиального процесса условие независимости не выполняется, поскольку известно общее количество точек. Если в область `\(A\)` попало `\(k\)` точек, то в область `\(B\)` не может попасть более чем `\(n-k\)` точек, что нарушает условие независимости распределений.

Предположение о независимости выполняется для любых непересекающихся регионов `\(A\)` и `\(B\)` и для любого числа этих регионов

---

### Пуассоновский процесс

Одним из следствий независимости является тот факт, что количество точек, подсчитанное по _регулярной сетке квадратов_, также даст совокупность независимых величин (для любого размера сетки):

![Baddeley et. al., 2016](images/qcounts.png)

---

## Пуассоновский процесс

__Упорядоченность__ _(orderliness)_: при стремлении площади области к нулю, вероятность нахождения в этой области более одной точки, деленная на площадь, также стремится к нулю

![:scale 50%](images/smalltrials.png)

---

### Пуассоновский процесс

Если реализации отвечают условию независимости и вероятность нахождения более одной точки в бесконечно малом квадрате пренебрежимо мала, то случайную величину `\(n(\mathbf{X} \cap B)\)` можно рассматривать как _количество «успехов» в большом числе независимых испытаний, каждое из которых имеет малую вероятность успеха_.

Это означает, что `\(n(\mathbf{X} \cap B)\)` подчиняется __распределению Пуассона__, которое характеризует _частоту редких событий_.

В соответствии с этим законом, вероятность получить `\(k\)` редких событий равна

`$$\mathbb{P}\{N = k\} = e^{-\mu} \frac{\mu^k}{k!}\color{grey}{,~k = 0, 1, 2, ...}$$`

Величина `\(\mu\)` представляет собой _математическое ожидание_ распределения Пуассона. 

---

### Пуассоновский процесс

`$$\mathbb{P}\{N = k\} = e^{-\mu} \frac{\mu^k}{k!}\color{grey}{,~k = 0, 1, 2, ...}$$`

Величина `\(\mu\)` представляет собой _математическое ожидание_ распределения Пуассона.

&gt; Дисперсия распределения Пуассона равна его математическому ожиданию

Поскольку, как мы показали ранее, ожидаемое количество точек в регионе `\(B\)` равняется `\(\operatorname E[n(\mathbf{X} \cap B)] = \lambda |B|\)`, можно сделать вывод, что случайная величина `\(n(\mathbf{X} \cap B)\)` имеет распределение Пуассона с математическим ожиданием:

`$$\mu = \lambda |B|$$`

---

### Пуассоновский процесс

Пуассоновский процесс определяется следующими __параметрами__:

- __однородность__: количество `\(n(\mathbf{X} \cap B)\)` случайных точек, попадающих в выборочную область `\(B\)` характеризуется мат. ожиданием `\(\mathbb{E}n(\mathbf{X} \cap B) = \lambda |B|\)`; 

- __независимость__: для неперекрывающихся выборочных областей `\(B_1, B_2, ..., B_k\)`, количества `\(n(\mathbf{X} \cap B_1), ..., n(\mathbf{X} \cap B_k)\)` предствляют собой независимые случайные величины;

- __распределение Пуассона__: число `\(n(\mathbf{X} \cap B)\)` случайных точек, попадающих в выборочную область `\(B\)` распределено по закону Пуассона.

---

### Пуассоновский процесс

__Свойства__ пуассоновского процесса:

- __условность__ _(conditional)_: в любой области `\(B\)` точки процесса независимо и равномерно распределены;

- __прореживаемость__ _(thinning)_: при случайном прореживании (отборе точек) пуассоновского точечного паттерна с интенсивностью `\(\lambda\)` результирующий паттерн будет соответствовать Пуассоновскому процессу с интенсивностью `\(p\lambda\)`, где `\(p\)` — вероятность сохранения точки (процент отбора);

    ![Baddeley et. al., 2016](images/pthinning.png)

---

### Пуассоновский процесс

__Свойства__ пуассоновского процесса:

- __суперпозиция__ _(superposition)_: сумма двух независимых гомогенных случайных точечных процессов `\(Z = X \cup Y\)` с интенсивностями `\(\lambda_X\)` и `\(\lambda_Y\)` является гомогенным Пуассоновским процессом с интенсивностью `\(\lambda_Z = \lambda_X + \lambda_Y\)`

    ![Baddeley et. al., 2016](images/psuperposition.png)

---

## Симуляция Пуассоновского процесса

Пусть дана область `\(B = [x_{min}, x_{max}] \times [y_{min}, y_{max}]\)` и интенсивность точечного процесса `\(\lambda\)`.

1. Сгенерировать случайное число `\(N\)`, имеющее распределение Пуассона с параметром `\(\mu = \lambda |B|\)`.

2. Сгенерировать `\(N\)` координат `\(X\)`, имеющих равномерное распределение на промежутке `\([x_{min}, x_{max}]\)`.

3. Сгенерировать `\(N\)` координат `\(Y\)`, имеющих равномерное распределение на промежутке `\([y_{min}, y_{max}]\)`.

&gt; Вероятность получить 0 точек также существует и равна `\(\mathbb{P}\{N = 0\} = e^{-\mu} \frac{\mu^0}{0!} = e^{-\lambda |B|}\)`

---

## Неоднородный пуассоновский процесс

Определяется следующими параметрами:

- __функция интенсивности__: количество `\(n(\mathbf{X} \cap B)\)` случайных точек, попадающих в выборочную область `\(B\)` характеризуется мат. ожиданием `\(\mathbb{E}n(\mathbf{X} \cap B) = \int_B \lambda(u) du = \mu\)`, где `\(\lambda(u)\)` есть пространственная функция интенсивности; 

- __независимость__: для неперекрывающихся выборочных областей `\(B_1, B_2, ..., B_k\)`, количества `\(n(\mathbf{X} \cap B_1), ..., n(\mathbf{X} \cap B_k)\)` предствляют собой независимые случайные величины;

- __распределение Пуассона__: число `\(n(\mathbf{B} \cap B)\)` случайных точек, попадающих в выборочную область `\(B\)` распределено по закону Пуассона.

---

## Неоднородный пуассоновский процесс

Данные параметры отличаются следующими свойствами:

- функция плотности `\(\lambda(u)\)` определяет общее количество точек и их пространственное распределение;

- никаких ограничений на функцию `\(\lambda(u)\)` не накладывается, вследствие этого модель неоднородного Пуассоновского процесса является достаточно общей;

- свойства условности, прореживаемости и суперпозиции справедливы также и для неоднородного пуассоновского процесса;

---

## Симуляция неоднородного пуассоновского процесса

Метод _Льюиса-Шедлера_ (Lewis-Shedler thinning):

1. Генерируется однородный Пуассоновской процесс с интенсивностью `\(M = \max_L\big[\lambda(u)\big]\)`.

2. Осуществляется случайное прореживание (исключение) точек с вероятностью сохранения точки `\(p(u) = \lambda(u) / M\)`, пропорциональной функции интенсивности.

Чтобы понять, будет ли точка исключена, генерируется случайное число 0 или 1, имеющее распределение Бернулли с вероятностью положительного исхода `\(p = p(u)\)`. Это можно сделать с помощью функции `rbinom(1, 1, p)`


---

## Симуляция неоднородного пуассоновского процесса

`$$\lambda(x,y) = x + y^2$$`

![](04-PointPatterns_slides_files/figure-html/unnamed-chunk-1-1.png)&lt;!-- --&gt;

---

## Процесс Кокса (Cox process)

Процесс Кокса определяется как Пуассоновский процесс со случайной функцией интенсивности `\(\Lambda(u)\)`, которая называется _порождающей интенсивностью_

![Baddeley et. al., 2016](images/cox.png)

Слева — реализация случайной функции `\(\Lambda(u)\)`. По центру — реализация Пуассоновского точечного процесса с интенсивностью `\(\Lambda(u)\)`.

---

## Процесс Кокса (Cox process)

- __Cмешанный Пуассоновский процесс__: однородный Пуассоновский процесс, порождаемый постоянной случайной величиной `\(\Lambda\)`. Интенсивность процесса равна `\(\lambda = \mathbb E\Lambda\)`.

- __Логнормальный процесс Кокса__: процесс Кокса с порождающей интенсивностью, равной `\(\Lambda(u) = \exp\big[G(u)\big]\)`, где `\(G(u)\)` — Гауссовское случайное поле.

Для _гауссовского случайного поля_ в каждой точке `\(u_i\)` случайная величина `\(G(u_i)\)` имеет нормальное распределение, для пары точек `\(u\)` и `\(v\)` пара величин `\(\big(G(u), G(v)\big)\)` имеет двумерное нормальное распределение. Аналогично и для произвольного числа точек.

---

## Процесс Кокса (Cox process)

Независимые реализации логнормального процесса Кокса:

![Baddeley et. al., 2016](images/coxnormal.png)

---

## Кластерные процессы

1. Генерируется «родительский» точечный процесс `\(\mathbf{Y}\)`.

2. Каждая точка родительского процесса `\(y_i\)` порождает случайный точечный паттерн «потомков» `\(x_{ij}\)`

![Baddeley et. al., 2016](images/clustered.png)

---

## Кластерные процессы

— Наблюдаются только точки потомков (каждая родительская точка замещается ее потомками).

— Множество точек `\(x_{ij}\)` формирует реализацию кластерного точечного процесса `\(\mathbf{X}\)`.

![Baddeley et. al., 2016](images/clustered.png)

---

## Кластерные процессы

Возможные свойства кластерных процессов:

- (CLP1) __пуассоновские родители__: родительские точки являются реализацией Пуассоновского процесса.

- (CLP2) __независимые кластеры__: кластеры независимы друг от друга.

- (CLP3) __идентично распределенные кластеры__: если совместить разные кластеры, то они будут иметь одно распределение.

- (CLP4) __независимые потомки__: потомки внутри каждого кластера независимы и одинаково распределены.

Процессы, отвечающие требованиям (CLP1)—(CLP4) носят название процессов __Неймана-Скотта__ (_Neyman-Scott_).

---

## Кластерные процессы

- (CLP5) __пуассоновское количество потомков__: для каждой родительской точки количество потомков есть пуассоновская случайная величина.

- (CLP6) __изотропные кластеры__: плотность распределения потомков зависит только от расстояния до родительской точки.

---

## Кластерные процессы

- Процесс Матерна `\((\kappa, \mu, r)\)`: процесс `\(Y\)` имеет интенсивность `\(κ\)`, каждый родитель имеет `\(Π(μ)\)` потомков, случайно распределенных в радиусе `\(r\)`

- Процесс Томаса `\((\kappa, \mu, \sigma)\)`: процесс `\(Y\)` имеет интенсивность κ, каждый родитель имеет `\(Π(μ)\)` потомков, смещенных на расстояние, подчиняющееся распределению `\(N(0,\sigma^2)\)`

---

## Кластерные процессы

Реализации процесса Матерна в квадрате `\([0, 1] \times [0, 1]\)` с интенсивностью родителей `\(\kappa = 8\)`, средним количеством потомков `\(\mu = 5\)` и радиусом кластера `\(R = 0.1\)`:

![Baddeley et. al., 2016](images/matern.png)

---

## Регулярные процессы

Точки не могут располагаться на расстоянии ближе чем `\(r\)` — __расстояния ингибиции__ (отталкивания).

- __Последовательные модели__: точки генерируются последовательно согласно Пуассоновскому распредедению (координаты равномерно распределены). Каждая последующая точка сохраняется, только если она находится на расстоянии не ближе, чем `\(r\)`.

- __Зависимое прореживание__: генерируется Пуассоновский процесс. После этого удаляются точки, расположенные на расстоянии меньшем `\(r\)`. Пары близко расположенных точек аннигилируют (_процесс Матерна I_). Либо точки маркируются случайным «временем прибытия» и удаляется точка, имеющая более позднее время прибытия (_процесс Матерна II_).

---

## Регулярные процессы

__Последовательная модель__:

![:scale 60%](images/rssi.png)

---

## Регулярные процессы

__Процесс Матерна I__:

![Baddeley et. al., 2016](images/matern1.png)

---

## Регулярные процессы

__Процесс Матерна II__:

![](images/matern2.png)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
